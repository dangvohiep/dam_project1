{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Project 1: Using PostgreSQL + Pandas for Data Management & Analysis \n","Group member:\n","1. Hiep Vo Dang"]},{"cell_type":"markdown","metadata":{},"source":["## Part 1: Introduction\n","\n","For my Project 1, I have chosen to work with the \"ATP Tennis Rankings, Results, and Stats\" dataset, which is forked from the repository maintained by Jeff Sackmann (https://github.com/JeffSackmann/tennis_atp#atp-tennis-rankings-results-and-stats).\n","\n","This dataset comprises detailed records of professional men's tennis matches, including individual player stats and match outcomes. From the vast dataset, I've specifically leveraged the files matching the pattern \"atp_matches_yyyy.csv\", intending to normalize this data into final fact tables and their associated dimension tables. \n","\n","My research primarily revolves around two core questions concerning the nuances of professional tennis. \n","\n","- First, I aim to determine if there's a correlation between a player's height and their serving prowess, essentially exploring whether taller players usually serve better. \n","- Second, I seek to understand the impact of a successful first serve; once a player gets their first serve in, how likely are they to win the point? \n","\n","Through this data exploration, I aim to discern patterns and relationships that might provide insights into the intricate dynamics of tennis gameplay, particularly emphasizing the pivotal role of serving."]},{"cell_type":"markdown","metadata":{},"source":["## Part 2: Data Summary\n","\n","The dataset houses primary ATP player details, historical rankings, match outcomes, and statistical insights.\n","\n","The author of this dataset has create many files to ease the use of the dataset, including:\n","- Player File: Attributes include `player_id`, `first_name`, `last_name`, `hand`, `birth_date`, `country_code`, and `height` (measured in cm).\n","- Ranking Files: Columns encompass `ranking_date`, `ranking`, `player_id`, and `ranking_points` (when available). ATP rankings are mostly comprehensive from 1985 onwards, with an absence in 1982 and sporadic entries from 1973-1984.\n","- Match Details: Each season typically has up to three files:\n","    + Main draw matches at the tour-level (e.g., `atp_matches_2014.csv`)\n","    + Tour-level qualifying and main-draw matches for challengers\n","    + Matches at the futures level.\n","\n","For the purpose of this project, which necessitates database normalization, I have narrowed down my focus to <u>only</u> files that provide statistical data on main draw matches at the tour level. These files can be identified by their naming convention, `atp_matches_yyyy.csv`, where `yyyy` represents the specific year.\n","\n","It's essential to note that while the overarching dataset does contain tables like `atp_players` and `atp_rankings`, <u>I have intentionally chosen not to interact with them</u>. The rationale behind this decision is to simulate a real-world scenario where I might only have access to the raw form of data, in this case, match statistics. My aim is to conduct the normalization process using this raw data as my sole data source in order to meet the requirements of this project.\n","\n","Given the availability of data within the ATP dataset, there are specific constraints in terms of the years I have chosen to focus on for this project. While the ATP rankings are largely comprehensive starting from 1985 up to the present day, the detailed statistics for tour-level matches only commence from 1991 onwards. Consequently, to ensure that the data I work with is both relevant and adequately detailed, I have decided to utilize files that range from `atp_matches_1991.csv` through to `atp_matches_2023.csv`. This range provides a substantial time span, ensuring a rich dataset while also aligning with the availability of detailed match statistics."]},{"cell_type":"markdown","metadata":{},"source":["## Part 3: Data Management using PostgreSQL"]},{"cell_type":"markdown","metadata":{},"source":["In order to get the data seemlessly from raw csv files hosted in a Github repository to my PostgreSQL database, I will develop an <b><u>ETL pipeline</u></b> (Extract, Transform and Load). The database is pre-created by the following script:\n","\n","```\n","-- tournaments table\n","create table if not exists \"tournaments\" (\n","    \"tourney_id\"        varchar(255)    primary key\n","    , \"tourney_name\"    varchar(255)    not null\n","    , \"tourney_level\"   varchar(255)\n","    , \"tourney_date\"    date\n","    , \"surface\"         varchar(255)\n","    , \"draw_size\"       integer\n",");\n","\n","-- players table\n","create table if not exists \"players\" (\n","    \"player_id\"         varchar(15)     primary key\n","    , \"name\"            varchar(255)    not null\n","    , \"hand\"            varchar(5)      check (\"hand\" in ('R', 'L', 'A', 'U'))\n","    , \"height\"          float\n","    , \"ioc\"             varchar(5)      not null\n","    , \"birth_year\"      integer\n",");\n","\n","-- matches table with surrogate key\n","create table if not exists \"matches\" (\n","    \"match_id\"          serial          primary key\n","    , \"season\"          integer         not null\n","    , \"tourney_id\"      varchar(255)    not null references \"tournaments\" (\"tourney_id\") on delete cascade\n","    , \"match_num\"       integer         not null\n","    , \"winner_id\"       varchar(15)     not null references \"players\" (\"player_id\") on delete cascade\n","    , \"loser_id\"        varchar(15)     not null references \"players\" (\"player_id\") on delete cascade\n","    , \"score\"           varchar(255)\n","    , \"best_of\"         integer\n","    , \"round\"           varchar(50)\n","    , \"minutes\"         integer\n","    , \"winner_aces\"            integer\n","    , \"winner_double_faults\"   integer\n","    , \"winner_serve_points\"    integer\n","    , \"winner_first_serve_in\"  integer\n","    , \"winner_first_serve_won\" integer\n","    , \"winner_second_serve_won\" integer\n","    , \"winner_service_games\"   integer\n","    , \"winner_break_points_saved\" integer\n","    , \"winner_break_points_faced\" integer\n","    , \"loser_aces\"            integer\n","    , \"loser_double_faults\"   integer\n","    , \"loser_serve_points\"    integer\n","    , \"loser_first_serve_in\"  integer\n","    , \"loser_first_serve_won\" integer\n","    , \"loser_second_serve_won\" integer\n","    , \"loser_service_games\"   integer\n","    , \"loser_break_points_saved\" integer\n","    , \"loser_break_points_faced\" integer\n","    , unique(\"season\", \"tourney_id\", \"match_num\")   -- ensures combination is unique\n",");\n","\n","-- rankings table\n","create table if not exists \"rankings\" (\n","    \"ranking_id\"        serial          primary key\n","    , \"season\"          integer         not null\n","    , \"tourney_id\"      varchar(255)    not null references \"tournaments\" (\"tourney_id\") on delete cascade\n","    , \"player_id\"       varchar(15)     not null references \"players\" (\"player_id\") on delete cascade\n","    , \"rank\"            float\n","    , \"points\"          float\n","    , unique(\"season\", \"tourney_id\", \"player_id\")   -- ensures combination of season and player_id is unique\n",");\n","\n","```"]},{"cell_type":"markdown","metadata":{},"source":["The resulting Entity Relation Diagram:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython import display\n","display.Image(\"\")"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.11.3 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.3"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"11b027f0300ad3990b7b2aff94caec0d55cdbf71c080e8dc203658a5d756feee"}}},"nbformat":4,"nbformat_minor":2}
